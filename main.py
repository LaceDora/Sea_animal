# -*- coding: utf-8 -*-
import os
# T·∫Øt log TensorFlow ƒë·ªÉ tr√°nh spam console
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' 

import sys
sys.stdout.reconfigure(encoding='utf-8')
import tensorflow as tf
import numpy as np
import json
import cv2
import time
from PyQt5.QtWidgets import (
    QApplication, QWidget, QPushButton, QLabel,
    QVBoxLayout, QHBoxLayout, QFileDialog
)
from PyQt5.QtGui import QPixmap, QImage, QFont
from PyQt5.QtCore import Qt, QTimer

# ===== Config =====
IMG_SIZE = 224
CONFIDENCE_THRESHOLD = 0.5

# Global variables for model and labels (will be loaded lazily)
model = None
class_names = None


def load_model_and_labels():
    """Load model and labels if not already loaded"""
    global model, class_names
    if model is None:
        print("Loading model...")
        try:
            # Th·ª≠ load b√¨nh th∆∞·ªùng
            model = tf.keras.models.load_model("seafood_model.keras")
        except Exception:
            print("Standard load failed, trying with compile=False...")
            # N·∫øu l·ªói, th·ª≠ load v·ªõi compile=False (b·ªè qua optimizer state)
            model = tf.keras.models.load_model("seafood_model.keras", compile=False)
            
        print("Model loaded successfully!")
    
    if class_names is None:
        print("Loading labels...")
        with open("labels.json", "r", encoding="utf-8") as f:
            class_names = json.load(f)
        print("Labels loaded successfully!")


def predict_image(img_path):
    # Ensure model is loaded
    load_model_and_labels()
    
    img = cv2.imread(img_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    img_array = cv2.resize(img_rgb, (IMG_SIZE, IMG_SIZE))
    img_array = np.expand_dims(img_array, axis=0)
    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)

    preds = model.predict(img_array, verbose=0)
    idx = np.argmax(preds[0])
    conf = float(np.max(preds[0]))

    pred_label = class_names[idx]

    if conf < CONFIDENCE_THRESHOLD:
        pred_show = f"Unknown ({pred_label})"
    else:
        pred_show = pred_label

    return img_rgb, pred_show, conf


def predict_frame(frame):
    """Predict from a camera frame"""
    load_model_and_labels()
    
    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    img_array = cv2.resize(img_rgb, (IMG_SIZE, IMG_SIZE))
    img_array = np.expand_dims(img_array, axis=0)
    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)

    preds = model.predict(img_array, verbose=0)
    idx = np.argmax(preds[0])
    conf = float(np.max(preds[0]))

    pred_label = class_names[idx]

    if conf < CONFIDENCE_THRESHOLD:
        label = "Unknown"
    else:
        label = pred_label

    return label, conf


class App(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Seafood Classifier - PyQt5")
        # C·ªë ƒë·ªãnh k√≠ch th∆∞·ªõc ƒë·ªÉ tr√°nh l·ªói layout b·ªã v·ª°/ph√¨nh to
        self.setFixedSize(1100, 700)

       
        self.header_label = QLabel("M√¥n: X·ª≠ L√Ω ·∫¢nh V√† Th·ªã Gi√°c M√°y T√≠nh\n Nh·∫≠n Di·ªán Sinh V·∫≠t Bi·ªÉn - Nh√≥m 09 ")

        self.header_label.setAlignment(Qt.AlignCenter)
        self.header_label.setFont(QFont("Arial", 35))
        self.header_label.setWordWrap(True) # Cho ph√©p xu·ªëng d√≤ng n·∫øu qu√° d√†i
        self.header_label.setStyleSheet("color: #222; font-weight: bold; margin-bottom: 20px;")

        # ================= Layout ch√≠nh =================
        main_layout = QHBoxLayout()
        control_layout = QVBoxLayout()
        image_layout = QVBoxLayout()

        # Hi·ªÉn th·ªã h√¨nh
        self.image_label = QLabel("No Image")
        self.image_label.setAlignment(Qt.AlignCenter)
        self.image_label.setFixedSize(500, 500)
        self.image_label.setStyleSheet("border: 3px dashed gray;")

        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        self.result_label = QLabel("Result: None")
        self.result_label.setAlignment(Qt.AlignCenter)
        self.result_label.setFont(QFont("Arial", 20))
        self.result_label.setStyleSheet("color: #222; font-weight: bold;")

        # N√∫t m·ªü ·∫£nh
        self.btn_open = QPushButton("üìÅ Open Image")
        self.btn_open.setFixedHeight(55)
        self.btn_open.setFont(QFont("Arial", 16))
        self.btn_open.clicked.connect(self.open_img)

        # N√∫t d·ª± ƒëo√°n
        self.btn_predict = QPushButton("Predict")
        self.btn_predict.setFixedHeight(55)
        self.btn_predict.setFont(QFont("Arial", 16))
        self.btn_predict.clicked.connect(self.predict)

        # N√∫t m·ªü camera
        self.btn_camera = QPushButton("M·ªü Camera")
        self.btn_camera.setFixedHeight(55)
        self.btn_camera.setFont(QFont("Arial", 16))
        self.btn_camera.clicked.connect(self.toggle_camera)

        # N√∫t tho√°t
        self.btn_exit = QPushButton("Tho√°t")
        self.btn_exit.setFixedHeight(55)
        self.btn_exit.setFont(QFont("Arial", 16))
        self.btn_exit.setStyleSheet("background-color: #d32f2f;")
        self.btn_exit.clicked.connect(self.exit_app)

        control_layout.addSpacing(60) 

        control_layout.addWidget(self.btn_open)
        control_layout.addWidget(self.btn_predict)
        control_layout.addSpacing(20)
        control_layout.addWidget(self.btn_camera)
        control_layout.addSpacing(20)
        control_layout.addWidget(self.btn_exit)

        control_layout.addStretch()
        control_layout.addWidget(self.result_label)
        control_layout.addSpacing(50)

        # Layout h√¨nh
        image_layout.addWidget(self.image_label)

        # Layout ch√≠nh HBox
        main_layout.addLayout(image_layout, 70)
        main_layout.addLayout(control_layout, 30)

        # ========= Layout t·ªïng c√≥ HEADER =========
        final_layout = QVBoxLayout()
        final_layout.addWidget(self.header_label)
        final_layout.addLayout(main_layout)

        self.setLayout(final_layout)
        self.current_img_path = None
        
        # Camera variables
        self.camera = None
        self.timer = None
        self.camera_active = False

    def open_img(self):
        # Stop camera if running
        if self.camera_active:
            self.stop_camera()
        
        path, _ = QFileDialog.getOpenFileName(
            self, "Ch·ªçn ·∫£nh", "", "Image Files (*.jpg *.jpeg *.png)"
        )
        if path:
            self.current_img_path = path

            img = cv2.imread(path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

            h, w, ch = img.shape
            bytes_per_line = ch * w
            qimg = QImage(img.data, w, h, bytes_per_line, QImage.Format_RGB888)

            pix = QPixmap.fromImage(qimg).scaled(
                500, 500, Qt.KeepAspectRatio, Qt.SmoothTransformation
            )

            self.image_label.setPixmap(pix)
            self.result_label.setText("Result: Ready")

    def predict(self):
        if not self.current_img_path:
            self.result_label.setText("‚ö† Please select an image first!")
            return

        try:
            # Hi·ªÉn th·ªã tr·∫°ng th√°i ƒëang x·ª≠ l√Ω
            self.result_label.setText("Processing...")
            QApplication.processEvents()  # C·∫≠p nh·∫≠t UI
            
            img, label, conf = predict_image(self.current_img_path)
            self.result_label.setText(f"{label} ({conf*100:.1f}%)")
            
        except Exception as e:
            # Hi·ªÉn th·ªã l·ªói ng·∫Øn g·ªçn tr√™n giao di·ªán
            error_str = str(e)
            if "Could not deserialize" in error_str:
                short_msg = "L·ªói phi√™n b·∫£n Model (Keras version mismatch)"
            elif "No such file" in error_str:
                short_msg = "Kh√¥ng t√¨m th·∫•y file model ho·∫∑c ·∫£nh"
            else:
                # L·∫•y 50 k√Ω t·ª± ƒë·∫ßu c·ªßa l·ªói ƒë·ªÉ hi·ªÉn th·ªã
                short_msg = f"L·ªói: {error_str[:50]}..."
            
            self.result_label.setText(short_msg)
            
            # In l·ªói chi ti·∫øt ra console ƒë·ªÉ debug
            print("-" * 30)
            print("CHI TI·∫æT L·ªñI:")
            print(error_str)
            print("-" * 30)
            import traceback
            traceback.print_exc()

    def toggle_camera(self):
        """Toggle camera on/off"""
        if self.camera_active:
            self.stop_camera()
        else:
            self.start_camera()

    def start_camera(self):
        """Start camera capture"""
        try:
            self.camera = cv2.VideoCapture(0)
            if not self.camera.isOpened():
                self.result_label.setText("‚ö† Cannot open camera!")
                return
            
            self.camera_active = True
            self.btn_camera.setText("D·ª´ng Camera")
            self.btn_camera.setStyleSheet("background-color: #f57c00;")
            self.result_label.setText("Camera: Active")
            
            # Create timer for updating frames
            self.timer = QTimer()
            self.timer.timeout.connect(self.update_frame)
            self.timer.start(30)  # Update every 30ms (~33 FPS)
            
        except Exception as e:
            self.result_label.setText(f"‚ö† Camera error: {str(e)[:50]}")
            print(f"Camera error: {e}")

    def stop_camera(self):
        """Stop camera capture"""
        self.camera_active = False
        if self.timer:
            self.timer.stop()
        if self.camera:
            self.camera.release()
        
        # Set black screen instead of frozen frame
        black_pixmap = QPixmap(500, 500)
        black_pixmap.fill(Qt.black)
        self.image_label.setPixmap(black_pixmap)
        
        self.btn_camera.setText("M·ªü Camera")
        self.btn_camera.setStyleSheet("")
        self.result_label.setText("Camera: Stopped")

    def update_frame(self):
        """Update frame from camera"""
        if not self.camera_active or not self.camera:
            return
        
        ret, frame = self.camera.read()
        if not ret:
            self.result_label.setText("‚ö† Failed to read from camera")
            return
        
        # Predict on frame
        try:
            label, conf = predict_frame(frame)
            
            # Convert frame to RGB for display
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # Display frame
            h, w, ch = frame_rgb.shape
            bytes_per_line = ch * w
            qimg = QImage(frame_rgb.data, w, h, bytes_per_line, QImage.Format_RGB888)
            pix = QPixmap.fromImage(qimg).scaled(
                500, 500, Qt.KeepAspectRatio, Qt.SmoothTransformation
            )
            self.image_label.setPixmap(pix)
            
            # Update result
            self.result_label.setText(f"Camera: {label} ({conf*100:.1f}%)")
            
        except Exception as e:
            print(f"Frame prediction error: {e}")

    def exit_app(self):
        """Exit the application"""
        if self.camera_active:
            self.stop_camera()
        QApplication.quit()

    def closeEvent(self, event):
        """Handle window close event"""
        if self.camera_active:
            self.stop_camera()
        event.accept()


# ===== Run App =====
if __name__ == "__main__":
    app = QApplication(sys.argv)
    
    with open("style.qss", "r", encoding="utf-8") as f:
        app.setStyleSheet(f.read())
    
    window = App()
    window.show()
    sys.exit(app.exec_())
